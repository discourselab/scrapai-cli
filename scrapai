#!/usr/bin/env python3
"""
scrapai - Simple Scrapy CLI for running Claude Code generated spiders with project support
"""

import argparse
import subprocess
import sys
import os
from pathlib import Path

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.project_manager import ProjectManager
from core.config_loader import ConfigLoader

def check_venv():
    """Check if we're in a virtual environment, warn if not"""
    if not hasattr(sys, 'real_prefix') and not (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):
        venv_path = Path('.venv')
        if venv_path.exists():
            print("âš ï¸  Virtual environment detected but not activated!")
            print("Run: source .venv/bin/activate")
            print("Then try again.\n")
        else:
            print("âš ï¸  No virtual environment found!")
            print("Run: uv venv && source .venv/bin/activate && uv pip install -r requirements.txt")
            print("Then try again.\n")
        return False
    return True

def main():
    if not check_venv():
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description='Run Scrapy spiders with project support')
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # projects command
    projects_parser = subparsers.add_parser('projects', help='Project management')
    projects_subparsers = projects_parser.add_subparsers(dest='projects_command', help='Project commands')
    
    # projects create
    create_parser = projects_subparsers.add_parser('create', help='Create a new project')
    create_parser.add_argument('--name', required=True, help='Project name')
    create_parser.add_argument('--spiders', required=True, help='Comma-separated spider names')
    
    # projects list
    projects_subparsers.add_parser('list', help='List all projects')
    
    # projects status
    status_parser = projects_subparsers.add_parser('status', help='Show project status')
    status_parser.add_argument('--project', required=True, help='Project name')
    
    # projects delete
    delete_parser = projects_subparsers.add_parser('delete', help='Delete a project')
    delete_parser.add_argument('--project', required=True, help='Project name')
    
    # crawl command
    crawl_parser = subparsers.add_parser('crawl', help='Run a spider')
    crawl_parser.add_argument('--project', required=True, help='Project name')
    crawl_parser.add_argument('spider', help='Spider name to run')
    crawl_parser.add_argument('--output', '-o', help='Output file path (optional, uses project config)')
    crawl_parser.add_argument('--limit', '-l', type=int, help='Limit number of items')
    
    # crawl-all command
    crawl_all_parser = subparsers.add_parser('crawl-all', help='Run all spiders in a project')
    crawl_all_parser.add_argument('--project', required=True, help='Project name')
    crawl_all_parser.add_argument('--limit', '-l', type=int, help='Limit number of items per spider')
    
    # list command
    list_parser = subparsers.add_parser('list', help='List available spiders')
    list_parser.add_argument('--project', help='Project name (optional)')
    
    # test command
    test_parser = subparsers.add_parser('test', help='Test a spider with limited items')
    test_parser.add_argument('--project', required=True, help='Project name')
    test_parser.add_argument('spider', help='Spider name to test')
    test_parser.add_argument('--limit', '-l', type=int, default=5, help='Number of items to test')
    
    # status command
    status_parser = subparsers.add_parser('status', help='Show project status')
    status_parser.add_argument('--project', required=True, help='Project name')
    
    # logs command
    logs_parser = subparsers.add_parser('logs', help='Show project logs')
    logs_parser.add_argument('--project', required=True, help='Project name')
    logs_parser.add_argument('--spider', help='Specific spider logs (optional)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Handle project management commands
    if args.command == 'projects':
        handle_projects_command(args)
    elif args.command == 'crawl':
        run_spider(args.project, args.spider, args.output, args.limit)
    elif args.command == 'crawl-all':
        run_all_spiders(args.project, args.limit)
    elif args.command == 'list':
        list_spiders(args.project)
    elif args.command == 'test':
        test_spider(args.project, args.spider, args.limit)
    elif args.command == 'status':
        show_project_status(args.project)
    elif args.command == 'logs':
        show_project_logs(args.project, args.spider)

def handle_projects_command(args):
    """Handle project management commands"""
    pm = ProjectManager()
    
    if args.projects_command == 'create':
        spiders = [s.strip() for s in args.spiders.split(',')]
        pm.create_project(args.name, spiders)
    elif args.projects_command == 'list':
        projects = pm.list_projects()
        if projects:
            print("ğŸ“‹ Available projects:")
            for project in projects:
                print(f"  â€¢ {project}")
        else:
            print("No projects found. Create one with: ./scrapai projects create --name <name> --spiders <spider1,spider2>")
    elif args.projects_command == 'status':
        status = pm.get_project_status(args.project)
        if 'error' in status:
            print(f"âŒ {status['error']}")
        else:
            print(f"ğŸ“Š Project: {status['name']}")
            print(f"ğŸ•·ï¸  Spiders: {', '.join(status['spiders'])}")
            print(f"ğŸ“„ Output files: {status['output_files']}")
            print(f"ğŸ“ Log files: {status['log_files']}")
            print(f"ğŸ“ Path: {status['path']}")
    elif args.projects_command == 'delete':
        confirm = input(f"Are you sure you want to delete project '{args.project}'? (y/N): ")
        if confirm.lower() == 'y':
            pm.delete_project(args.project)
        else:
            print("âŒ Delete cancelled")

def run_spider(project_name, spider_name, output_file=None, limit=None):
    """Run a Scrapy spider for a specific project"""
    config_loader = ConfigLoader()
    
    try:
        # Validate project and spider
        if not config_loader.validate_spider_for_project(project_name, spider_name):
            print(f"âŒ Spider '{spider_name}' not found or not configured for project '{project_name}'")
            return
        
        # Get project settings
        settings = config_loader.get_spider_settings(project_name, spider_name)
        
        # Build scrapy command
        cmd = ['scrapy', 'crawl', spider_name]
        
        # Add settings
        for key, value in settings.items():
            if key not in ['FEEDS', 'LOG_FILE']:  # These are handled differently
                cmd.extend(['-s', f'{key}={repr(value)}'])
        
        # Handle output
        if output_file:
            cmd.extend(['-o', output_file])
        elif 'FEEDS' in settings:
            # Use project-configured output
            pass
        
        # Handle log file
        if 'LOG_FILE' in settings:
            cmd.extend(['-s', f'LOG_FILE={settings["LOG_FILE"]}'])
        
        if limit:
            cmd.extend(['-s', f'CLOSESPIDER_ITEMCOUNT={limit}'])
        
        print(f"ğŸš€ Running spider: {spider_name} (project: {project_name})")
        subprocess.run(cmd)
        
    except Exception as e:
        print(f"âŒ Error running spider: {e}")

def run_all_spiders(project_name, limit=None):
    """Run all spiders configured for a project"""
    config_loader = ConfigLoader()
    
    try:
        spiders = config_loader.get_project_spiders(project_name)
        if not spiders:
            print(f"âŒ No spiders configured for project '{project_name}'")
            return
        
        print(f"ğŸš€ Running all spiders for project: {project_name}")
        print(f"ğŸ•·ï¸  Spiders: {', '.join(spiders)}")
        
        for spider in spiders:
            print(f"\n{'='*50}")
            print(f"Running: {spider}")
            print(f"{'='*50}")
            run_spider(project_name, spider, None, limit)
            
    except Exception as e:
        print(f"âŒ Error running spiders: {e}")

def test_spider(project_name, spider_name, limit=5):
    """Test a spider with limited items"""
    print(f"ğŸ§ª Testing spider: {spider_name} (project: {project_name}, limit: {limit})")
    run_spider(project_name, spider_name, None, limit)

def list_spiders(project_name=None):
    """List available spiders"""
    if project_name:
        # List spiders for specific project
        config_loader = ConfigLoader()
        try:
            spiders = config_loader.get_project_spiders(project_name)
            print(f"ğŸ“‹ Spiders configured for project '{project_name}':")
            for spider in spiders:
                print(f"  â€¢ {spider}")
        except Exception as e:
            print(f"âŒ Error: {e}")
    else:
        # List all available spiders
        print("ğŸ“‹ Available spiders:")
        spiders_dir = Path("spiders")
        if spiders_dir.exists():
            for spider_file in spiders_dir.glob("*.py"):
                if spider_file.name != "__init__.py" and spider_file.name != "base_spider.py":
                    spider_name = spider_file.stem
                    print(f"  â€¢ {spider_name}")
        else:
            print("  No spiders found. Ask Claude Code to create some!")

def show_project_status(project_name):
    """Show project status"""
    pm = ProjectManager()
    status = pm.get_project_status(project_name)
    
    if 'error' in status:
        print(f"âŒ {status['error']}")
    else:
        print(f"ğŸ“Š Project: {status['name']}")
        print(f"ğŸ•·ï¸  Spiders: {', '.join(status['spiders'])}")
        print(f"ğŸ“„ Output files: {status['output_files']}")
        print(f"ğŸ“ Log files: {status['log_files']}")
        print(f"ğŸ“ Path: {status['path']}")

def show_project_logs(project_name, spider_name=None):
    """Show project logs"""
    pm = ProjectManager()
    
    if not pm.project_exists(project_name):
        print(f"âŒ Project '{project_name}' not found")
        return
    
    logs_dir = pm.get_project_path(project_name) / "logs"
    
    if not logs_dir.exists():
        print(f"ğŸ“ No logs found for project '{project_name}'")
        return
    
    if spider_name:
        # Show specific spider logs
        log_file = logs_dir / f"{spider_name}.log"
        if log_file.exists():
            print(f"ğŸ“ Logs for {spider_name} (project: {project_name}):")
            print("-" * 50)
            with open(log_file, 'r') as f:
                print(f.read())
        else:
            print(f"âŒ No logs found for spider '{spider_name}' in project '{project_name}'")
    else:
        # Show all log files
        log_files = list(logs_dir.glob("*.log"))
        if log_files:
            print(f"ğŸ“ Log files for project '{project_name}':")
            for log_file in log_files:
                print(f"  â€¢ {log_file.name}")
        else:
            print(f"ğŸ“ No log files found for project '{project_name}'")

if __name__ == '__main__':
    main()